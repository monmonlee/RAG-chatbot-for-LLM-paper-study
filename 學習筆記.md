**AIMessage資料型態**
```python
response = llm.invoke("你好")
print(type(response))  # <class 'langchain_core.messages.ai.AIMessage'>
print(response)        # AIMessage(content='你好！有什麼可以幫助你的嗎？', ...)
```
- AIMessage是langchain的標準化格式(和Document Loader的邏輯差不多)，包含：
    - content：文字內容
    - matadata：模型資訊、token內容鄧
    - response_metadata：api回應的詳細資訊

- 所以如果想要返回llm提供的json內容，需要擷取內容的部分：
    ```python
    response = llm.invoke(query)
    respose_text = response.content
    # 然後再解析json檔
    import json
    metadata = json.loads(respose_text.strip())
    ```

**llm生成的結構化文字通常使用json**
- 判斷：今天希望llm生成的是「直接的結果」，還是「給其他程式使用」？
    - 前者 → output為文字；後者 → json
- json 檔優勢
    - 結構化比純文字更容易解析
    - llm熟悉json格式
    - 可快速檢查格式與內容
    - 可直接轉換成python dict

**語法 `dict.get()`**
- 用途：用來從 dict 裡面透過key取值
    ```python
    dict.get("key", default) # key 就是對應的鍵，default就是不存在會返回的東西（預設none）
    ```
- 優勢：`dict[key]`如果找不到，會報錯（`KeyError`）；但`dict.get()`不會

**hybrid檢索的機制說明**
- 在 llm 的檢索中，我們總共會有四種檢索情況「年份＋主題、純年份、純主題、都沒有」，所以適合用`if-elif-else`來處理
- 透過`candidate`篩選出一定範圍的塊（k=k*3），在過濾出`candidate`裡面符合metadata的項目
- 示範如下：
    ```python 
    
    # 假設已經解析matadata：

    if year and topic:
        candidate = vectorbd.max_marginal_relevance_search(query, k=k*4)
        filter = [doc for doc in candidate 
                    if doc.metadata.get('year') == year
                    and doc.metadata.get('topic') == topic ]
    ```
- 補充：duck typing & 真值判斷：為什麼可以直接寫成`if year and topic:`
    - 每個值都有「真」「假」特性，if 通常都是預設「為真」，所以可以省略不寫。
    - 如果要預設找「假」→ `if not(year and topic)`
    - 使用時機：如果只是要排查是否有值，可以直接省略不寫
    - 特殊情況：
        ```python
        # 當0是有效值時
            age = 0  # 0歲是有效年齡
            score = 0  # 0分是有效分數

            if age:     #  False! 因為0被預設是false，但其實0歲是有效的
            if score:   #  False! 

            # 正確寫法
            if age is not None:     # 
            if score is not None:   # 
            if age >= 0:           #  更精確的條件
        ```

**try/except機制**
- LLM 程式常用 try/except 
- 原因：llm返回的結果是「不確定性的」，時常出錯，例如：
    - 網路問題：api請求中斷等等的
    - 模型名稱錯誤：例如我剛剛的‘turbo’大寫就會報錯
    - api限制：例如使用額度不夠
    - 輸出格式不合：llm回傳的json格式錯誤之類的
    - 資料問題：輸入的prompt超過token限制之類的
-  try/except可以為程式加上保護，捕捉錯誤並處理，避免錯誤中斷