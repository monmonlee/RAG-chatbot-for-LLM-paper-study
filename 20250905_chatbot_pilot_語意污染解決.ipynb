{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立整體的ui介面，變成一個問答機器人\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import RetrievalQA,  ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一步測試：載入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "目的：建立langchain + openai 的基礎環境\n",
    "'''\n",
    "import os # 作業系統相關功能（讀取環境變數）\n",
    "from openai import OpenAI # openai api 客戶端\n",
    "from dotenv import load_dotenv, find_dotenv # dotenv 是專門用來讀取.env套件的套件，並接上環境\n",
    "_ = load_dotenv(find_dotenv()) # 讀取.env檔案\n",
    "client = OpenAI(\n",
    "    api_key=os.environ['OPENAI_API_KEY']\n",
    ")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success! API key loaded\n",
      "Key starts with: sk-proj-FWUUter...\n",
      "Key length: 164 characters\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 清除舊的環境變數\n",
    "if 'OPENAI_API_KEY' in os.environ:\n",
    "    del os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# 重新載入\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ.get('OPENAI_API_KEY')\n",
    "if api_key:\n",
    "    print(\"✅ Success! API key loaded\")\n",
    "    print(f\"Key starts with: {api_key[:15]}...\")\n",
    "    print(f\"Key length: {len(api_key)} characters\")\n",
    "else:\n",
    "    print(\"❌ Still not working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder exists: True\n",
      "Found 24 PDF files:\n",
      "  - 2023_LLM limitation_Large Language Models Sensitivity to The Order of Options in Multiple-Choice Questions.pdf\n",
      "  - 2025_LLM limitation_The Order Effect- Investigating Prompt Sensitivity to Input Order in LLMs.pdf\n",
      "  - 2024_RAG_Evaluation of Retrieval-Augmented Generation- A Survey.pdf\n",
      "  - 2020_scaling laws_Scaling Laws for Neural Language Models.pdf\n",
      "  - 2022_LLM limitation_Robustness of Learning from Task Instructions.pdf\n"
     ]
    }
   ],
   "source": [
    "# 檢查資料夾是否存在\n",
    "import os\n",
    "folder_path = \"/Users/mangtinglee/Desktop/2025_gap_careerpath/RAG_LLM/pdfs\"\n",
    "\n",
    "print(f\"Folder exists: {os.path.exists(folder_path)}\")\n",
    "# 看看有哪些PDF檔案\n",
    "pdf_files = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "print(f\"Found {len(pdf_files)} PDF files:\")\n",
    "for pdf in pdf_files[:5]:  # 顯示前5個檔名\n",
    "    print(f\"  - {pdf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2025/09/11 目前進度\n",
    "- 已經完成所有過程跑過一遍\n",
    "- 上週五（9/5）發現問題：問「結論」，llm回答「找不到結論」，但明明其中一章就是結論\n",
    "- 判定問題：語意污染與雜訊過多，llm被不同章節的「結論干擾」，無法回應結論那一章的內容 → 需要定義好每一篇章節分類\n",
    "- 9/5，原本打算用llm分類再放到每一塊中，實際執行困難，因為llm標注準確率較低\n",
    "- 改為手動內容篩選，只保留每篇論文的第一頁，只想要 Abstract + Introduction開頭\n",
    "- 後來改為只想要Abstract，並且手動建立一份ｃｓｖ meta data\n",
    "- 9/11 進度規劃：\n",
    "    - 載入檔案時，自動對應metadata\n",
    "    - 重新跑一遍，並測試效果\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'title'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 76\u001b[0m\n\u001b[1;32m     73\u001b[0m csv_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/Users/mangtinglee/Desktop/2025_gap_careerpath/RAG_LLM/meta_data_correction.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[39m# 載入\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m all_abstracts_with_metadata \u001b[39m=\u001b[39m load_all_first_pages_with_csv_metadata(folder_path, csv_path)\n\u001b[1;32m     78\u001b[0m \u001b[39m# 檢查結果\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39mfor\u001b[39;00m i, doc \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(all_abstracts_with_metadata[:\u001b[39m3\u001b[39m]):\n",
      "Cell \u001b[0;32mIn[16], line 26\u001b[0m, in \u001b[0;36mload_all_first_pages_with_csv_metadata\u001b[0;34m(folder_path, csv_path)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"載入PDF第一頁並從CSV對應metadata\"\"\"\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m# 1. 先讀取metadata對應表\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m metadata_map \u001b[39m=\u001b[39m load_metadata_mapping(csv_path)\n\u001b[1;32m     27\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m載入metadata對應表，共 \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(metadata_map)\u001b[39m}\u001b[39;00m\u001b[39m 筆資料\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m all_first_pages \u001b[39m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[16], line 15\u001b[0m, in \u001b[0;36mload_metadata_mapping\u001b[0;34m(csv_path)\u001b[0m\n\u001b[1;32m     12\u001b[0m metadata_map \u001b[39m=\u001b[39m {}\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m _, row \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m     14\u001b[0m     metadata_map[row[\u001b[39m'\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m=\u001b[39m {\n\u001b[0;32m---> 15\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m: row[\u001b[39m'\u001b[39;49m\u001b[39mtitle\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     16\u001b[0m         \u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m: row[\u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     17\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mauthors\u001b[39m\u001b[39m'\u001b[39m: row[\u001b[39m'\u001b[39m\u001b[39mauthors\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     18\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mtopic\u001b[39m\u001b[39m'\u001b[39m: row[\u001b[39m'\u001b[39m\u001b[39mtopic\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     19\u001b[0m     }\n\u001b[1;32m     20\u001b[0m \u001b[39mreturn\u001b[39;00m metadata_map\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m   1123\u001b[0m \u001b[39m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[39m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[39mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1239\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'title'"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. 簡化版：只要第一頁\n",
    "import pandas as pd\n",
    "\n",
    "def load_metadata_mapping(csv_path):\n",
    "    \"\"\"讀取CSV檔案建立metadata對應表\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # 將filename作為key，其他資訊作為value\n",
    "    metadata_map = {}\n",
    "    for _, row in df.iterrows():\n",
    "        metadata_map[row['filename']] = {\n",
    "            'title': row['title'],\n",
    "            'year': row['year'],\n",
    "            'authors': row['authors'],\n",
    "            'topic': row['topic']\n",
    "        }\n",
    "    return metadata_map\n",
    "\n",
    "def load_all_first_pages_with_csv_metadata(folder_path, csv_path):\n",
    "    \"\"\"載入PDF第一頁並從CSV對應metadata\"\"\"\n",
    "    \n",
    "    # 1. 先讀取metadata對應表\n",
    "    metadata_map = load_metadata_mapping(csv_path)\n",
    "    print(f\"載入metadata對應表，共 {len(metadata_map)} 筆資料\")\n",
    "    \n",
    "    all_first_pages = []\n",
    "    pdf_files = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"處理：{pdf_file}\")\n",
    "        \n",
    "        file_path = os.path.join(folder_path, pdf_file)\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        documents = loader.load()\n",
    "        \n",
    "        # 只取第一頁\n",
    "        first_page_docs = filter_first_page_only(documents)\n",
    "        \n",
    "        # 🎯 關鍵：從CSV對應metadata\n",
    "        for doc in first_page_docs:\n",
    "            if pdf_file in metadata_map:\n",
    "                # 找到對應的metadata\n",
    "                doc.metadata.update(metadata_map[pdf_file])\n",
    "                print(f\"  ✅ 已更新metadata: {metadata_map[pdf_file]['title']}\")\n",
    "            else:\n",
    "                # 找不到對應資料\n",
    "                print(f\"  ⚠️  警告：{pdf_file} 在CSV中找不到對應資料\")\n",
    "                doc.metadata.update({\n",
    "                    'title': pdf_file.replace('.pdf', ''),\n",
    "                    'year': None,\n",
    "                    'authors': 'Unknown',\n",
    "                    'topic': 'Unknown'\n",
    "                })\n",
    "        \n",
    "        all_first_pages.extend(first_page_docs)\n",
    "    \n",
    "    print(f\"總共載入 {len(all_first_pages)} 個第一頁，metadata已更新\")\n",
    "    return all_first_pages\n",
    "\n",
    "\n",
    "\n",
    "def filter_first_page_only(documents):\n",
    "    \"\"\"只保留第一頁（Abstract）\"\"\"\n",
    "    first_page_docs = [doc for doc in documents if doc.metadata['page'] == 0]\n",
    "    print(f\"原始頁數：{len(documents)} → 只保留第一頁：{len(first_page_docs)} 頁\")\n",
    "    return first_page_docs\n",
    "\n",
    "\n",
    "# 執行\n",
    "csv_path = \"/Users/mangtinglee/Desktop/2025_gap_careerpath/RAG_LLM/meta_data_correction.csv\"\n",
    "\n",
    "# 載入\n",
    "all_abstracts_with_metadata = load_all_first_pages_with_csv_metadata(folder_path, csv_path)\n",
    "\n",
    "# 檢查結果\n",
    "for i, doc in enumerate(all_abstracts_with_metadata[:3]):\n",
    "    print(f\"\\n--- Document {i+1} ---\")\n",
    "    print(f\"Title: {doc.metadata.get('title', 'N/A')}\")\n",
    "    print(f\"Year: {doc.metadata.get('year', 'N/A')}\")\n",
    "    print(f\"Authors: {doc.metadata.get('authors', 'N/A')}\")\n",
    "    print(f\"Topic: {doc.metadata.get('topic', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二步測試：分割檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "# 測試2. 分割檔案\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, \n",
    "    chunk_overlap=50,\n",
    "    separators=[ \"\\n\\n\", \". \", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    "    )    \n",
    "docs = text_splitter.split_documents(all_abstracts)\n",
    "print(len(docs)) # chunks\n",
    "print(len(all_abstracts)) # test 11 pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-12T00:55:20+00:00', 'author': '', 'keywords': '', 'moddate': '2025-05-12T00:55:20+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '/Users/mangtinglee/Desktop/2025_gap_careerpath/RAG_LLM/pdfs/2025_LLM limitation_The Order Effect- Investigating Prompt Sensitivity to Input Order in LLMs.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(docs[10].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以我的理解是這一大段落其實是先抓取原始documents（已經過loader但還沒splits的檔案），先用正則辨識出大概的標題section_headers，在用llm去辨識section_headers屬於哪種分類嗎？\n",
    "因為我的檔案有些標題無法辨識他是研究結果或方法，例如5 Calibrating LLMs for MCQ Tasks，所以我的想法是，我們是否到時候可以直接先分塊，假設分了54塊，我們再請llm讀取54塊，然後讓他貼標（複數）？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第三步測試：embedding 並放入資料庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish！\n",
      "資料夾存在嗎？True\n"
     ]
    }
   ],
   "source": [
    "# 建立資料庫路徑，已有路徑則可忽略\n",
    "import os\n",
    "\n",
    "# 建立資料夾\n",
    "os.makedirs('./chroma_db', exist_ok=True)\n",
    "print(\"finish！\")\n",
    "\n",
    "# 檢查是否成功\n",
    "print(f\"資料夾存在嗎？{os.path.exists('./chroma_db')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define embedding\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意，需要先在自己的環境中建立資料庫路徑\n",
    "persist_directory = './chroma_db' # 指定資料庫路徑\n",
    "!rm -rf ./chroma_db  # remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立新的向量資料庫，並將文件放進去\n",
    "from langchain.vectorstores import Chroma\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      ". Many of these issues, such as bias (Talat et al., 2022; Motoki\n",
      "et al., 2023), hallucination (Chen et al., 2023; Sadat et al., 2023), consistency (Tam et al., 2023; Ye\n",
      "et al., 2023), and reliability (Shen et al., 2023b) have been extensively discussed in the literature.\n",
      "However, a more fundamental challenge to the long-term success of LLMs is their ability to reason:\n",
      "the distinguishing factor between probabilistic pattern matching and logical understanding. This\n",
      "distinction has significant implications for the future of LLMs and how we employ these models in\n",
      "decision-making.\n",
      "One necessary requirement for reasoning is order independence. A model should provide the same\n",
      "consistent response to a query regardless of the order of its content. Historically, LLMs have strug-\n",
      "gled with this issue. Swapping subsequences within semantically identical inputs often leads to\n",
      "significant changes in output, a problem that worsens as inputs grow in size and complexity (He\n",
      "et al., 2024)\n"
     ]
    }
   ],
   "source": [
    "question = \"can you explain llm limitation?\"\n",
    "ans_docs = vectordb.similarity_search(question,k=3)\n",
    "print(len(ans_docs))\n",
    "print(ans_docs[2].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_x/xcmm2w3d1hld6_nc6t0xyrch0000gn/T/ipykernel_93325/2355425439.py:2: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "# 手動儲存剛剛建立的資料庫\n",
    "vectordb.persist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Prompt Report: A Systematic Survey of Prompt Engineering\\nTechniques\\nSander Schulhoff1,2∗ Michael Ilie1∗Nishant Balepur1 Konstantine Kahadze1\\nAmanda Liu1 Chenglei Si4 Yinheng Li5 Aayush Gupta1 HyoJung Han1 Sevien Schulhoff1\\nPranav Sandeep Dulepet1 Saurav Vidyadhara1 Dayeon Ki1 Sweta Agrawal12 Chau Pham13\\nGerson Kroiz Feileen Li 1 Hudson Tao1 Ashay Srivastava1 Hevander Da Costa1 Saloni Gupta1\\nMegan L'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define retriever 改成使用mmr\n",
    "retriever = vectordb.as_retriever(\n",
    "    search_type=\"mmr\", \n",
    "    search_kwargs={\n",
    "        \"k\": 3,\n",
    "        \"fetch_k\":20\n",
    "        }\n",
    "    )\n",
    "question = \"is there any author named Jean Kaddour ?\"\n",
    "docs_mmr = vectordb.max_marginal_relevance_search(question,k=3)\n",
    "docs_mmr[2].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SPANISH AND LLM B ENCHMARKS : IS MMLU L OST IN\\nTRANSLATION ?\\nA PREPRINT\\nIrene Plaza, Nina Melero, Cristina del Pozo, Javier Conde and Pedro Reviriego\\nETSI de Telecomunicación\\nUniversidad Politécnica de Madrid\\n28040 Madrid, Spain\\nMarina Mayor-Rocher\\nFacultad de Filosofía y Letras\\nUniversidad Autónoma de Madrid\\n28049 Madrid, Spain\\nMaría Grandury\\nSomosNLP\\n24402, Ponferrada, Spain\\nJune 27, 2024\\nABSTRACT\\nThe evaluation of Large Language Models (LLMs) is a key element in their continuous improvement\\nprocess and many benchmarks have been developed to assess the performance of LLMs in different\\ntasks and topics. As LLMs become adopted worldwide, evaluating them in languages other than\\nEnglish is increasingly important. However, most LLM benchmarks are simply translated using\\nan automated tool and then run in the target language. This means that the results depend not\\nonly on the LLM performance in that language but also on the quality of the translation'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_mmr[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'. . . . . . 36\\n3.3 Computer Programming . . . . . 37\\n*Equal contribution.\\n†{jean.kaddour,robert.mchardy}.20@ucl.ac.uk,\\njoshua.harris@ukhsa.gov.uk\\nDesign\\nUnfathomable \\nDatasets, \\nTokenizer-Reliance,\\nFine-Tuning \\nOverhead\\nScience\\n \\nEvaluations \\nBased \\non \\nStatic \\nHuman-Written \\nGround \\nTruth,\\nLacking \\nExperimental \\nDesigns,\\nLack \\nof \\nReproducibility\\nBehavior\\nPrompt \\nBrittleness, \\nMisaligned \\nBehavior,\\nOutdated \\nKnowledge\\nDetecting \\nGenerated \\nTexts, \\nBrittle \\nEvaluations\\nHigh \\nPre-Training \\nCosts\\nHigh \\nInference \\nLatency, \\nLimited \\nContext \\nLength, \\nHallucinations\\nTasks \\nNot \\nSolvable\\nBy \\nScale\\nFigure 1: Overview of LLM Challenges. Designing\\nLLMs relates to decisions taken before deployment. Be-\\nhaviorial challenges occur during deployment. Science\\nchallenges hinder academic progress.\\n3.4 Creative Work . . . . . . . . . . . 39\\n3.5 Knowledge Work . . . . . . . . . 40\\n3.6 Law . . . . . . . . . . . . . . . . 42\\n3.7 Medicine . . . . . . . . . . . . . 43\\n3.8 Reasoning . . . . . . . . . . . .'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_mmr[2].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_x/xcmm2w3d1hld6_nc6t0xyrch0000gn/T/ipykernel_93325/1656567243.py:12: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model_name=llm_name, temperature=0)\n",
      "/var/folders/_x/xcmm2w3d1hld6_nc6t0xyrch0000gn/T/ipykernel_93325/1656567243.py:13: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  llm.predict(\"Hello world!\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 選擇模型\n",
    "import datetime\n",
    "current_date = datetime.datetime.now().date()\n",
    "if current_date < datetime.date(2023, 9, 2):\n",
    "    llm_name = \"gpt-3.5-turbo-0301\"\n",
    "else:\n",
    "    llm_name = \"gpt-3.5-turbo\"\n",
    "print(llm_name)\n",
    "\n",
    "# 初始化聊天機器人要用到的llm\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=llm_name, temperature=0)\n",
    "llm.predict(\"Hello world!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_x/xcmm2w3d1hld6_nc6t0xyrch0000gn/T/ipykernel_93325/2717514122.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "# 新項目：載入ConversationBufferMemory\n",
    "# 此套件能讓問答機器人記住過往歷史問答\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", # 告訴 chain 去哪裡找歷史對話\n",
    "    return_messages=True, # 返回的是物件（長得像json or meta data）\n",
    "    output_key=\"answer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm=ChatOpenAI(model_name=llm_name, temperature=0), \n",
    "        chain_type=\"map_reduce\", \n",
    "        retriever=retriever, \n",
    "        return_source_documents=True,\n",
    "        return_generated_question=True,\n",
    "        memory=memory\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation methods for Large Language Models (LLMs) include using benchmarks to assess performance in tasks such as common sense reasoning problems and mathematical questions. Some benchmarks evaluate multiple tasks to provide a more comprehensive evaluation of LLM capabilities. However, evaluations for LLMs are based on static human-written ground truth, which has been criticized for lacking experimental designs and reproducibility. Additionally, evaluations suffer from prompt brittleness, misaligned behavior, outdated knowledge, and challenges in detecting generated texts and conducting evaluations due to various factors like high pre-training costs, high inference latency, limited context length, and hallucinations.\n"
     ]
    }
   ],
   "source": [
    "question = \"What evaluation methods are used for LLMs?\"\n",
    "result = qa({\"question\": question})\n",
    "print(result['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The names of the references for the limitations of Large Language Models (LLMs) mentioned earlier are Jean Kaddour, Joshua Harris, Maximilian Mozes, Herbie Bradley, Roberta Raileanu, Robert McHardy, Zhao et al., 2021, and Wang et al., 2023b.\n"
     ]
    }
   ],
   "source": [
    "question = \"can you show me the reference's name of those three llm's limitations you gave me before?\"\n",
    "result = qa({\"question\": question})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
